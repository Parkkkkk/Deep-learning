# TIL ( 2021/01/20 )

- Error Metrics for Skewed Classes

---

## Error Metrics for Skewed Classes

왜곡된 클래스(skewed class)는 positive, negative data의 비율이 어느 한쪽으로 치우쳐진것을 말한다. 그럼 이게 왜 치명적인 문제가 될 수 있을까?

  

예를 들어 우리가 학습을 통해서 binary classification을 하는 어떤 classifier를 만들었고 positive data가 99개 negative data가 1개라고 했을때 이런 skewed class의 경우에 알고리즘이 실제와 다르게 높은 정확도와 낮은 오류율을 출력하기 때문에 이 classifier는 정확하다고 할 수가 없다. 

  

#### Precision/Recall

그래서 이런 경우에는 Precision(정밀도), Recall(재현율)을 보고 평가하는것이 더 좋은 방법이다.

  

실제 정답과 분류 결과를 각각 case별로 나눠서 살펴보면 다음과 같다.

- True Positive(TP) : GT가 True인 정답을 True라고 예측
- False Positive(FP) : GT가 False인 정답을 True라고 예측
- False Negative(FN) : GT가 True인 정답을 False라고 예측
- True Negative(TN) : GT가 False인 정답을 False라고 예측

  

Precision은 우리가 만들 알고리즘이 True라고 분류한것중에 실제 True인것의 비율로 식은 아래와 같다.

  

<a href="https://www.codecogs.com/eqnedit.php?latex=Precision&space;=&space;\frac{TP}{TP&space;&plus;&space;FP}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?Precision&space;=&space;\frac{TP}{TP&space;&plus;&space;FP}" title="Precision = \frac{TP}{TP + FP}" /></a>

 

Recall(재현율)은 GT가 True인 것 중에서 알고리즘이 True라고 예측한 것에 비율로 식은 아래와 같다.

  

<a href="https://www.codecogs.com/eqnedit.php?latex=Recall=&space;\frac{TP}{TP&space;&plus;&space;FN}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?Recall=&space;\frac{TP}{TP&space;&plus;&space;FN}" title="Recall= \frac{TP}{TP + FN}" /></a>

  

다시 정리해서 둘은 얼핏보면 비슷해 보이지만 Precision은 검출된 결과가 얼마나 실제 검출하고자하는 물체들을 포함하고 있는지를 나타내는것이고 Recall은 물체들을 얼마나 



## Reference

- https://www.coursera.org/learn/machine-learning

