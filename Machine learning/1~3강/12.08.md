# TIL ( 2020/12/08 )

- The problem of overfitting

---

## The problem of Overfitting

먼저 overfitting이란 학습 데이터를 과하게 잘 학습하는것을 뜻하는데 다시 말해서 학습 데이터에 대해 과하게 학습이 되어서 실제 데이터에 대한 오차가 증가하는 현상을 말한다.

좀 더 자세히 설명하자면 Feature가 많아질수록 Hypothesis function이 복잡해지는데 우리의 목적은 training set과 완벽하게 똑같은 모델을 만드는것이 아니라 새로운 데이터에 대해서 정확하게 예측하는 것이다. 하지만 학습이 과하게 되면 model은 오히려 새로운 데이터를 예측하는데 실패 할 수 있다는것이다.



## Adressing Overfitting

우리가 어떤 모델을 학습 시켰을때 이게 overfitting이 되었는지 어떻게 알 수 있을까? 대표적으로 feature가 엄청 많을 경우나 다항식이 고차원일때 발생한다고 한다.

  

Overftting을 해결하는 방법은 크게 2가지가 있는데, 

  

- **Reduce number of features**
  - Feature들을 보고 필요한것과 불필요한것을 판단하여 불필요한것은 제거한다.
  - Model Selection algorithm(뒤에서 배운다)

  

이렇게 feature의 수를 줄이는 방법으로 방지 할수 있지만 제거하는 feature중에 중요한 정보를 담고있는것을 같이 제거 할 수도 있다는 문제가 있다. 

  

- **Regularization**
  - 모든 feature들을 남기되 각각의 feature가 미치는 영향을 줄인다. 
  - 각각의 feature가 예측값 y에 조금씩 다 기여할 경우 유용



****

>## Reference

- https://www.coursera.org/learn/machine-learning
- https://wikidocs.net/4288

